# Sprint 1

Main activities identified are:
1. Exploring fusion methodologies
2. Extracting spatio-temporal patterns from available datasets and cleaning up data (data cleaning/preparation)

To achieve a generalised fused product, good spatio-temporal variation with the input data must be achieved (as well as reference dataset). This is largely achieved through the data preparation stage, of which the following considerations must be taken into account:
* To include the spatial and temporal dimension, the time points for each dataset must be known. For the model data, daily averages from the unstructured mesh are interpolated onto a structured grid. To-do: visual check on the interpolation; export data in 10-min timeseries; export data for the 10-11am UTC hourly average to harmonise with satellite data
* (Nice-have): For the satellite data, perhaps images that coincide with the low tidal cycles can be removed, and EOF or gap filling can be done on the remaining images. Images that coincide with low tidal cycles risk more flats being exposed and could also be confused for wet/dry pixels. At the moment, the choice is made to keep the methodology as generically applicable as possible

For 1:
* Main spatio-temporal fusion methodologies such as Bayesian, Gaussian-averaging and 4DVarNet were explored
* Each methodology is assessed on performance, ease-of-implementation (is the code easy to apply) and other relevant considerations
* All methodologies share some common needs: sufficiently spatio-temporally varying data for training/calibration
* Two caveats emerge: A successfully fused product will require sufficiently spatially and temporally varying input data
* At the moment, MWTL data is almost one dimension (varies in time but not in space)
* At the moment, satellite data has no sensing time in the metadata. However, based on the archive of Sentinel-2A and 2B data, typical sensing times are between 10-11am UTC. An average of 10:30am UTC is taken as an assumption, with uncertainty of +/-30 min
* Must keep in mind that the total number of 'match-ups' between model, satellite and MWTL data are not very much for 2017, but the fusion methodology can still be set up.

For 2:
* Data cleaning/preparation:
  * Originally, it was assumed that the Delft3D FM interpolation only introduced artefacts at the domain boundaries. If that is the case, a simple mask can be applied that removes non-physical values (e.g. concnetrations above 400 mg/l, threshold to be verified).
  * Based on the above mentioned visual check on the interpolation we might find out that other artefacts have been introduced. In that case we have two options: (1) acknowledge and document this short coming but due to tiem constraints proceed with the current interpolated product (after removing outliers), or (2) try a better interpolation method from other projects (e.g. GTSM)
* Extracting spatio-temporal patterns using EOF:
  * The purpose of EOF method was explored. EOF can be applied to a univariate spatio-temporal data (e.g. only SPM  field of the model or satellite). The identified patters show covarying locations. The identified pattern therefore captures replicate information otherwise stored in the many individual time series.  
  * Example implementation: https://podaac.jpl.nasa.gov/forum/viewtopic.php?f=5&t=337
  * Probably most convenient package: https://ajdawson.github.io/eofs/latest/
  * Another python tool (Mario): https://pyeof.readthedocs.io/en/latest/notebooks/basic_usage.html
  * Recommended steps for implementation: first replicate the example and then apply it on our data (Deflt3D FM and satellite)
